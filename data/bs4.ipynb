{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sydney Greenspun",
   "id": "3fccbc302f4cab50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:00:39.701714Z",
     "start_time": "2025-07-30T19:00:39.131914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "all_languages = {}\n",
    "\"\"\"\n",
    "This is a wikipedia page that contains languages with 50 million or more speakers and information about their language families. This lists includes dialects which I hope to flush out. I use this as the base for my dataset.\n",
    "\"\"\"\n",
    "try:\n",
    "    html = urlopen('https://en.wikipedia.org/wiki/List_of_languages_by_total_number_of_speakers')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "\n",
    "    bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "    table = bs.find('table')\n",
    "    for row in table.find_all('tr')[2:]:\n",
    "        cols = row.find_all(['th', 'td'])\n",
    "        lang = re.sub(r\"\\(.*?\\)\", \"\", cols[0].text.strip())\n",
    "        if lang == \"Modern Standard Arabic\":\n",
    "            lang= \"Arabic\"\n",
    "        if lang == \"Mandarin Chinese\":\n",
    "            lang = \"Chinese\"\n",
    "        if lang == \"Standard German\":\n",
    "            lang = \"German\"\n",
    "        if lang == \"Western Punjabi\":\n",
    "            lang = \"Punjabi\"\n",
    "        if lang == \"Tagalog[b]\":\n",
    "            lang = \"Tagalog\"\n",
    "        if lang == \"Iranian Persian\":\n",
    "            lang = \"Persian\"\n",
    "        all_languages[lang] = {}\n",
    "        all_languages[lang][\"Family\"] = cols[1].getText(strip=True)\n",
    "        all_languages[lang][\"Branch\"] = cols[2].getText(strip=True)\n",
    "        all_languages[lang][\"Speakers (in millions)\"] = cols[5].getText(strip=True)\n"
   ],
   "id": "55752c32c973ddfd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:00:39.887915Z",
     "start_time": "2025-07-30T19:00:39.729447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spoken_list = {}\n",
    "\"\"\"\n",
    "This is from the WorldData and contains a list of languages and the number of countries in which they are spoken\n",
    "\"\"\"\n",
    "try:\n",
    "    html2 = urlopen('https://www.worlddata.info/languages/')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    bs2 = BeautifulSoup(html2.read(), 'html.parser')\n",
    "    table = bs2.find('table')\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        #for some reason getText didn't work\n",
    "        spoken_list[cols[0].text] ={}\n",
    "        spoken_list[cols[0].text][\"Countries\"] = int(cols[1].text.split(' ')[0])\n",
    "\n"
   ],
   "id": "30916af448193fd8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:00:41.269924Z",
     "start_time": "2025-07-30T19:00:40.893488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iso_codes = {}\n",
    "\"\"\"\n",
    "Another Wikipedia page that has a chart of languages and their ISO names.\n",
    "\"\"\"\n",
    "try:\n",
    "    html4 = urlopen('https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    bs4 = BeautifulSoup(html4.read(), 'html.parser')\n",
    "    table = bs4.find('table')\n",
    "    current_language = None\n",
    "    for row in table.find_all(\"tr\")[2:]:\n",
    "        cols = row.find_all([\"th\", \"td\"])\n",
    "        if \",\" in cols[0].getText(strip=True):\n",
    "            language = cols[0].getText(strip=True)[:cols[0].getText(strip=True).index(\",\")]\n",
    "        else:\n",
    "            language = cols[0].getText(strip=True)\n",
    "        iso_codes[language] = {}\n",
    "        iso_codes[language][\"ISO-Code\"]= cols[1].text\n"
   ],
   "id": "aa8d21c82cbeabb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:27:43.907431Z",
     "start_time": "2025-07-30T19:27:43.638733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_scripts = {}\n",
    "\"\"\"\n",
    "This page is a Wikipedia page that contains a list of scripts as headers and their associated languages below the headers in a list. I mapped the languages to the header they were below\n",
    "\"\"\"\n",
    "try:\n",
    "    html5 = urlopen('https://simple.wikipedia.org/wiki/List_of_languages_by_writing_system')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    bs5 = BeautifulSoup(html5.read(), 'html.parser')\n",
    "    for heading in bs5.find_all(\"div\", class_=['mw-heading2', 'mw-heading3']):\n",
    "        script = heading.getText(strip=True)\n",
    "        script = re.sub(r'\\[.*\\]', '', script)\n",
    "        script = script.split(\" \")[0]\n",
    "        if script == \"ArabicScript\":\n",
    "            script = \"Arabic\"\n",
    "        ul = heading.find_next_sibling('ul')\n",
    "        if not ul:\n",
    "            continue\n",
    "        for li in ul.find_all('li'):\n",
    "            lang = re.sub(r\"\\(.*?\\)\", \"\", li.getText(strip=True))\n",
    "            if lang:\n",
    "                new_scripts.setdefault(lang, {}).setdefault(\"script\", []).append(script)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "1b3569f178ca66be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic\n",
      "Armenian\n",
      "Borama\n",
      "Brahmic\n",
      "Devanagari\n",
      "Assamese/Bengali\n",
      "Balinese\n",
      "Baybayin\n",
      "Buhid\n",
      "Burmese\n",
      "Gujarati\n",
      "Gurmukhi\n",
      "Hanun√≥'o\n",
      "Javanese\n",
      "Kannada\n",
      "Khmer\n",
      "Lao\n",
      "Lepcha\n",
      "Limbu\n",
      "Lontara\n",
      "Malayalam\n",
      "Oriya\n",
      "'Phags-pa\n",
      "Sinhala\n",
      "Tagbanwa\n",
      "Tamil\n",
      "Telugu\n",
      "Thaana\n",
      "Thai\n",
      "Tibetan\n",
      "Canadian\n",
      "Cherokee\n",
      "Constructed\n",
      "Aiha\n",
      "Argpal\n",
      "Cirth\n",
      "Ewellic\n",
      "Klingon\n",
      "Tengwar\n",
      "Tolianem\n",
      "Coptic\n",
      "Cyrillic\n",
      "Bosnian\n",
      "Saba\n",
      "Georgian\n",
      "Glagolitic\n",
      "Gothic\n",
      "Greek\n",
      "Chinese\n",
      "Hangul\n",
      "Hebrew\n",
      "Jurchen\n",
      "Kaddare\n",
      "Kana\n",
      "Khitan\n",
      "Latin\n",
      "Mayan\n",
      "Mongolian\n",
      "Old\n",
      "Mongolian\n",
      "Manchu\n",
      "Munda\n",
      "Sorang\n",
      "Ol\n",
      "Warang\n",
      "N'Ko\n",
      "Naxi\n",
      "Nsibidi\n",
      "Ogham\n",
      "Osmanya\n",
      "Pahawh\n",
      "Runic\n",
      "Old\n",
      "Orkhon\n",
      "Syriac\n",
      "Tifinagh\n",
      "Yi\n",
      "References\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f106415a5765dd42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T19:44:07.559565Z",
     "start_time": "2025-07-30T19:44:07.537073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iso = [{'language': k, **v} for k, v in iso_codes.items()]\n",
    "language_facts = [{'language': k, **v} for k, v in all_languages.items()]\n",
    "spoken = [{'language': k, **v} for k, v in spoken_list.items()]\n",
    "scripts_list = [{'language': k, **v} for k, v in new_scripts.items()]\n",
    "\n",
    "iso_df = pd.DataFrame(iso)\n",
    "language_facts_df = pd.DataFrame(language_facts)\n",
    "spoken_df = pd.DataFrame(spoken)\n",
    "scripts_df = pd.DataFrame(scripts_list)\n",
    "merged = pd.merge(iso_df, language_facts_df, on='language', how='right')\n",
    "merged2 = pd.merge(merged, spoken_df, on='language', how='left')\n",
    "final = pd.merge(merged2, scripts_df, on='language', how='left')\n",
    "final.to_csv('/Users/sbg/PycharmProjects/language-wiki/data/scraped_data.csv', index=False)\n"
   ],
   "id": "9200ac1f7a0fc54",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T22:08:41.735645Z",
     "start_time": "2025-07-26T22:05:59.342785Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "72e3455a653d449a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T22:08:41.737341Z",
     "start_time": "2025-07-26T22:05:37.961553Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8184388e8d58518",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
